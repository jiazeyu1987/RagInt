import React, { useState, useRef } from 'react';
import './App.css';

function App() {
  const [isRecording, setIsRecording] = useState(false);
  const [question, setQuestion] = useState('');
  const [answer, setAnswer] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        stream.getTracks().forEach(track => track.stop());
        await processAudio(audioBlob);
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (err) {
      console.error('Error accessing microphone:', err);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  const processAudio = async (audioBlob) => {
    setIsLoading(true);
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob);

      const response = await fetch('http://localhost:8000/api/speech_to_text', {
        method: 'POST',
        body: formData
      });

      const result = await response.json();
      const text = result.text || '';

      if (text) {
        await askQuestion(text);
      } else {
        setIsLoading(false);
      }
    } catch (err) {
      console.error('Error processing audio:', err);
      setIsLoading(false);
    }
  };

  const askQuestion = async (text) => {
    setQuestion(text);
    setAnswer('');
    setIsLoading(true);

    try {
      const response = await fetch('http://localhost:8000/api/ask', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ question: text })
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let fullAnswer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6));
              if (data.chunk && !data.done) {
                fullAnswer += data.chunk;
                setAnswer(fullAnswer);
              }
              if (data.done) {
                console.log('RAGFlowå“åº”å®Œæˆï¼Œå¼€å§‹TTSæ’­æ”¾');
                console.log('å®Œæ•´å›ç­”æ–‡æœ¬:', fullAnswer);
                await playTTS(fullAnswer);
                return;
              }
            } catch (err) {
              console.error('Error parsing chunk:', err);
            }
          }
        }
      }
    } catch (err) {
      console.error('Error asking question:', err);
      setIsLoading(false);
    }
  };

  const playTTS = async (text) => {
    try {
      console.log('å¼€å§‹æµå¼TTSè¯­éŸ³åˆæˆï¼Œæ–‡æœ¬é•¿åº¦:', text.length);
      console.log('TTSæ–‡æœ¬å†…å®¹:', text);

      const response = await fetch('http://localhost:8000/api/text_to_speech_stream', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text: text })
      });

      console.log('TTSæµå¼å“åº”çŠ¶æ€:', response.status);

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡è¿›è¡Œæµå¼æ’­æ”¾
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      let chunks = [];
      let totalBytes = 0;

      const reader = response.body.getReader();

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        chunks.push(value);
        totalBytes += value.length;
        console.log('æ”¶åˆ°éŸ³é¢‘chunkï¼Œå¤§å°:', value.length);
      }

      console.log('éŸ³é¢‘æµæ¥æ”¶å®Œæˆï¼Œæ€»å¤§å°:', totalBytes);

      // åˆå¹¶æ‰€æœ‰chunk
      const audioData = new Uint8Array(totalBytes);
      let offset = 0;
      for (const chunk of chunks) {
        audioData.set(chunk, offset);
        offset += chunk.length;
      }

      // è§£ç éŸ³é¢‘å¹¶æ’­æ”¾
      try {
        console.log('å¼€å§‹è§£ç éŸ³é¢‘...');
        const audioBuffer = await audioContext.decodeAudioData(audioData.buffer);
        console.log('éŸ³é¢‘è§£ç æˆåŠŸï¼Œæ—¶é•¿:', audioBuffer.duration);

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);

        source.onended = () => {
          console.log('æµå¼éŸ³é¢‘æ’­æ”¾ç»“æŸ');
          setIsLoading(false);
          audioContext.close();
        };

        source.start(0);
        console.log('æµå¼éŸ³é¢‘æ’­æ”¾å¼€å§‹');

      } catch (decodeError) {
        console.error('éŸ³é¢‘è§£ç å¤±è´¥:', decodeError);

        // å¦‚æœè§£ç å¤±è´¥ï¼Œå°è¯•ä½œä¸ºblobæ’­æ”¾
        const audioBlob = new Blob([audioData], { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);

        audio.onended = () => {
          console.log('å¤‡ç”¨éŸ³é¢‘æ’­æ”¾ç»“æŸ');
          URL.revokeObjectURL(audioUrl);
          setIsLoading(false);
          audioContext.close();
        };

        await audio.play();
        console.log('å¤‡ç”¨éŸ³é¢‘æ’­æ”¾å¼€å§‹');
      }

    } catch (err) {
      console.error('æµå¼TTSè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:', err);
      setIsLoading(false);
    }
  };

  const handleTextSubmit = async (e) => {
    e.preventDefault();
    if (question.trim() && !isLoading) {
      await askQuestion(question);
    }
  };

  return (
    <div className="app">
      <div className="container">
        <h1>AIè¯­éŸ³é—®ç­”</h1>

        <div className="input-section">
          <div className="voice-input">
            <button
              className={`record-btn ${isRecording ? 'recording' : ''}`}
              onMouseDown={startRecording}
              onMouseUp={stopRecording}
              onTouchStart={startRecording}
              onTouchEnd={stopRecording}
              disabled={isLoading}
            >
              {isRecording ? 'ğŸ”´ å½•éŸ³ä¸­...' : 'ğŸ¤ æŒ‰ä½è¯´è¯'}
            </button>
          </div>

          <form className="text-input" onSubmit={handleTextSubmit}>
            <input
              type="text"
              value={question}
              onChange={(e) => setQuestion(e.target.value)}
              placeholder="æˆ–è€…è¾“å…¥æ–‡å­—é—®é¢˜..."
              disabled={isLoading}
            />
            <button type="submit" disabled={isLoading}>
              å‘é€
            </button>
          </form>
        </div>

        {question && (
          <div className="question-section">
            <h3>é—®é¢˜: {question}</h3>
          </div>
        )}

        {answer && (
          <div className="answer-section">
            <h3>å›ç­”:</h3>
            <p>{answer}</p>
          </div>
        )}

        {isLoading && (
          <div className="loading">
            å¤„ç†ä¸­...
          </div>
        )}
      </div>
    </div>
  );
}

export default App;